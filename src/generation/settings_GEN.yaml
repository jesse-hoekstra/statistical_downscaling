global:
  seed: 888
  RNG_NAMESPACE: 20260115
  generation_type: 'conditional'
  mode: 'sample'
  train_denoiser: False
  train_pde: True
  continue_training: False
  data_file_name: 'data/ks_trajectories_512.h5'
  d: 192
  d_prime: 24
  T: 1
  output_dir: 'src/generation/output/'
  time_emb_dim: 16
  chunk_size_sampler: 16
  hyperparameter_tuning: True
train_denoiser:
  batch_size: 512 
  total_train_steps: 1_000_000 
  eval_every_steps: 100 
  metric_aggregation_steps: 100 
  save_interval_steps: 100 
  num_batches_per_eval: 10 
  max_to_keep: 1
  beta_min: 0.1
  beta_max: 20 
  norm_guide_strength: 1.0
  ema_decay: 0.95
  clip_min: 1e-3 
UNET:
  out_channels: 1
  num_channels: 32,64,128
  downsample_ratio: 2,2,2
  num_blocks: 6
  noise_embed_dim: 128
  use_attention: True
  num_heads: 8
  use_position_encoding: False
  dropout_rate: 0.0
optimizer:
  init_value: 0.0
  peak_value: 1e-3
  warmup_steps: 1_000
  decay_steps: 990_000
  end_value: 1e-6
  clip_norm: 1.0
  clip_gradient: 200_000.0
  use_clip_gradient: False
exp_tspan:
  num_steps: 256
  end_sigma: 1e-2 #not defined specifically in the paper
pde_solver:
  t_low: 1e-10
  nSim_interior: 1000 
  nSim_terminal: 1000 
  x_low: -5.0
  x_high: 5.0
  y_low: -5.0
  y_high: 5.0
  sampling_stages: 75_000 
  type_lr_schedule: sirignano 
  constant_lr: 1e-3
  boundaries: [25_000, 50_000]
  lr_schedules: [1e-3, 5e-4, 1e-4]
  lambda: 1 
  num_gen_samples: 128 
  num_conditionings: 512 
  chunk_size: 250
  adaptive_balancing_loss: False
  lambda_smooth_alpha: 0.1
  normalize_data: False
DGM:
  nodes_per_layer: 256
  num_layers: 5
ema:
  ema_decay: 0.999
  use_ema_eval: True
wandb:
  use_wandb: False
metrics: 
  log_ema_metrics_every: 500
  log_train_metrics_every: 50
  epsilon: 1e-5










