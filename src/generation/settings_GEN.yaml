global:
  seed: 888
  RNG_NAMESPACE: 20260115
  generation_type: 'conditional'
  mode: 'eval'
  train_denoiser: False
  train_pde: True
  continue_training: False
  data_file_name: 'data/ks_trajectories_512.h5'
  d: 192
  d_prime: 24
  T: 1
  output_dir: 'src/generation/output/'
  rng_key: 888
  epsilon: 1e-5
  time_emb_dim: 16
train_denoiser:
  batch_size: 512 #32 for runthrough
  total_train_steps: 50 #1_000_000  for runthrough
  eval_every_steps: 10 #100 for runthrough
  metric_aggregation_steps: 10 #100 for runthrough
  save_interval_steps: 10 #100  for runthrough
  num_batches_per_eval: 1 #10  for runthrough #not defined specifically in the paper
  max_to_keep: 1
  beta_min: 0.1
  beta_max: 20 
  norm_guide_strength: 1.0
  ema_decay: 0.95
  clip_min: 1e-3 
UNET:
  out_channels: 1
  num_channels: 32,64,128
  downsample_ratio: 2,2,2
  num_blocks: 6
  noise_embed_dim: 128
  use_attention: True
  num_heads: 8
  use_position_encoding: False
  dropout_rate: 0.0
optimizer:
  init_value: 0.0
  peak_value: 1e-3
  warmup_steps: 1_000
  decay_steps: 990_000
  end_value: 1e-6
  clip_norm: 1.0
exp_tspan:
  num_steps: 256
  end_sigma: 1e-2 #not defined specifically in the paper
pde_solver:
  t_low: 1e-10
  nSim_interior: 1000 #Batch size
  nSim_terminal: 1000 #Batch size
  x_low: -5.0
  x_high: 5.0
  y_low: -5.0
  y_high: 5.0
  sampling_stages: 75_000 #100_000 
  type_lr_schedule: sirignano #set to specific value for fixed learning rate
  constant_lr: 1e-3
  boundaries: [25000, 50000]
  lr_schedules: [1e-3, 5e-4, 1e-4]
  lambda: 1 #to start with
  num_gen_samples: 128 # 128 8 is pde_solver on local machine 15360
  num_conditionings: 16 # 512 aka num_conditions 16 is pde_solver on local machine
  chunk_size: 250
DGM:
  nodes_per_layer: 256
  num_layers: 5
  N_epochs: 1_250
ema:
  ema_decay: 0.999
  use_ema_eval: True
easy_examples:
  n_samples_train: 38_400
  n_samples_generate: 20_000
  dt: 0.0001
wandb:
  use_wandb: True
metrics: 
  log_ema_metrics_every: 500
  log_train_metrics_every: 50










